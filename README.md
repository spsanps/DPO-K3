# DPO-K3
Implementation of K=3 alternative to dpo_trainer.py @ https://github.com/huggingface/trl.git
